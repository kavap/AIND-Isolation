{
    "critiques": {
        "680": {
            "rubric_items": {
                "5510": {
                    "result": "failed",
                    "observation": "{\n    \"14. Submission includes heuristic_analysis.pdf\": {\n        \"traceback\": \"AssertionError: False is not true : You must submit a report named heuristic_analysis.pdf for review.\\n\"\n    }, \n    \"15. Submission includes research_review.pdf\": {\n        \"traceback\": \"AssertionError: False is not true : You must submit a report named research_review.pdf for review.\\n\"\n    }, \n    \"6. Test the interface of AlphaBetaPlayer.get_move()\": {\n        \"traceback\": \"AssertionError: False is not true : The AlphaBetaPlayer.get_move() function failed as player 1 on an empty board. It should return coordinates on the game board for the location of the agent's next move. The move must be one of the legal moves on the current game board. Your function returned (-1, -1) which is not in the list of legal moves [(0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (7, 0), (8, 0), (0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (0, 2), (1, 2), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2), (7, 2), (8, 2), (0, 3), (1, 3), (2, 3), (3, 3), (4, 3), (5, 3), (6, 3), (7, 3), (8, 3), (0, 4), (1, 4), (2, 4), (3, 4), (4, 4), (5, 4), (6, 4), (7, 4), (8, 4), (0, 5), (1, 5), (2, 5), (3, 5), (4, 5), (5, 5), (6, 5), (7, 5), (8, 5), (0, 6), (1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6), (7, 6), (8, 6), (0, 7), (1, 7), (2, 7), (3, 7), (4, 7), (5, 7), (6, 7), (7, 7), (8, 7), (0, 8), (1, 8), (2, 8), (3, 8), (4, 8), (5, 8), (6, 8), (7, 8), (8, 8)]\\n\"\n    }, \n    \"7. Test functionality of AlphaBetaPlayer.alphabeta()\": {\n        \"traceback\": \"AssertionError: False is not true : Your AlphaBetaAgent.alphabeta function did not call the heuristic evaluation function in all of the expected set of leaf nodes configurations in the game tree as player 1. Make sure that you are using the self.score() method to evaluate the board (not calling one of your heuristic functions directly) and verify your stopping conditions. Leaf nodes are shown as (player_1, player_2) location pairs. Optional nodes may or may not be visited depending on your termination test.\\n\\nExpected leaf nodes:\\n{((6, 3), (1, 5)), ((5, 2), (1, 5)), ((3, 6), (1, 5)), ((6, 5), (1, 5)), ((2, 5), (1, 5)), ((5, 6), (1, 5))}\\nOptional leaf nodes:\\nset()\\nLeaf nodes your agent evaluated:\\n{((2, 5), (0, 7)), ((3, 6), (3, 4)), ((6, 5), (2, 7)), ((6, 5), (0, 7)), ((5, 6), (3, 6)), ((5, 2), (3, 6)), ((6, 3), (3, 4)), ((6, 5), (3, 4)), ((3, 6), (2, 7)), ((5, 6), (0, 7)), ((3, 6), (0, 3)), ((5, 2), (3, 4)), ((2, 5), (3, 4)), ((6, 5), (3, 6)), ((5, 2), (0, 7)), ((5, 2), (2, 7)), ((6, 3), (0, 7)), ((6, 5), (0, 3)), ((2, 5), (0, 3)), ((2, 5), (3, 6)), ((3, 6), (0, 7)), ((6, 3), (2, 7)), ((5, 6), (0, 3)), ((2, 5), (2, 7)), ((5, 6), (2, 7)), ((6, 3), (3, 6)), ((6, 3), (0, 3)), ((5, 6), (3, 4)), ((5, 2), (0, 3))}\\nSkipped nodes:\\n{((6, 3), (1, 5)), ((5, 2), (1, 5)), ((3, 6), (1, 5)), ((6, 5), (1, 5)), ((2, 5), (1, 5)), ((5, 6), (1, 5))}\\nExtra nodes:\\n{((2, 5), (0, 7)), ((3, 6), (3, 4)), ((6, 5), (2, 7)), ((6, 5), (0, 7)), ((5, 6), (3, 6)), ((5, 2), (3, 6)), ((6, 3), (3, 4)), ((6, 5), (3, 4)), ((3, 6), (2, 7)), ((5, 6), (0, 7)), ((3, 6), (0, 3)), ((5, 2), (3, 4)), ((2, 5), (3, 4)), ((6, 5), (3, 6)), ((5, 2), (0, 7)), ((5, 2), (2, 7)), ((6, 3), (0, 7)), ((6, 5), (0, 3)), ((2, 5), (0, 3)), ((2, 5), (3, 6)), ((3, 6), (0, 7)), ((6, 3), (2, 7)), ((5, 6), (0, 3)), ((2, 5), (2, 7)), ((5, 6), (2, 7)), ((6, 3), (3, 6)), ((6, 3), (0, 3)), ((5, 6), (3, 4)), ((5, 2), (0, 3))}\\n\\nTest Case Details:\\n------------------\\nHeuristic: open_move_score\\nDepth limit: 1\\nInitial Board State:\\n     0   1   2   3   4   5   6   7   8\\n\\r0  |   |   |   |   |   |   |   |   |   | \\n\\r1  |   |   |   |   |   | 2 |   |   |   | \\n\\r2  |   |   | - | - |   |   | - |   |   | \\n\\r3  |   |   | - |   |   |   |   |   |   | \\n\\r4  |   | - | - | - | 1 | - |   |   |   | \\n\\r5  |   |   |   | - | - | - |   |   |   | \\n\\r6  |   |   |   |   |   |   | - |   |   | \\n\\r7  |   |   |   |   |   |   |   |   |   | \\n\\r8  |   |   |   |   |   |   |   |   |   | \\n\\r\\ngame._board_state:\\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 40]\\n\\n\"\n    }\n}"
                }
            }
        }
    }
}